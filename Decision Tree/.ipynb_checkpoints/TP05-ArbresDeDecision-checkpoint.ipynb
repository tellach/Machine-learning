{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Les arbres de décision \n",
    "\n",
    "Un arbre de décision est un modèle d'apprentissage automatique très simple. \n",
    "Il a été largement utilisé dans les années 1960-1980 pour la construction de systèmes experts. \n",
    "Il est largement connu et utilisé dans de nombreuses entreprises pour faciliter le processus de prise de décision et l'analyse des risques. \n",
    "\n",
    "Etant donnée plusieurs caractéristiques, la décision se commence par un de ces caractéristiques; si ce n'ai pas suffisant, on utilise une autre, ainsi de suite. \n",
    "Les règles sont introduites manuellement, pour cette raison ce modèle a perdu sa popularité après les années 80. L'apparition des méthodes mathématiques pour construire les arbres de décision fait revenir ce modèle à la bataille des algorithmes de l'apparentissage automatique.\n",
    "Il existe plusieurs algorithmes automatiques pour construire les arbres de décision :\n",
    "\n",
    "* ID3 (Iterative Dichotomiser 3): dévelopé en 1986 par Ross Quinlan. Il peut être appliqué seulement sur les caractéristiques nominales. Il est utilisé pour le classement.\n",
    "* C4.5: une extension de ID3 par Ross Quinlan. Il peut être appliqué sur tous les types de caractéristiques. Il est utilisé pour le classement.\n",
    "* C5.0: une extension commerciale de C4.5, toujours par Ross Quinlan.\n",
    "* CART (Classification and Regression Trees): comme C4.5 mais utilise d'autres métriques. Aussi, l'algorithme supporte la régression.\n",
    "\n",
    "L'algorithme général de création d'un arbre de décision :\n",
    "\n",
    "* Déterminer la meilleure caractéristique dans l'ensemble de données d'entrainement.\n",
    "* Diviser les données d'entrainement en sous-ensembles contenant les valeurs possibles de la meilleure caractéristique.\n",
    "* Générez de manière récursive de nouveaux arbres de décision en utilisant les sous-ensembles de données créés.\n",
    "* Lorsqu'on ne peut plus classifier les données, on s'arrête.\n",
    "\n",
    "## Avantages \n",
    "\n",
    "* Ils sont simples à comprendre et à interpréter. On peut visualiser les arbres. Aussi, on peut expliquer les résulats oubtenus facilement.\n",
    "* Ils peuvent travailler sur des données avec peu de préparation. Par exemple, ils n'ont pas besoin de la normalisation des données.\n",
    "* Ils acceptent les données numériques et nominales. Les autres algorithmes d'apprentissage sont spécialisés dans un seul type de données.\n",
    "* Ils donnent de bonne performance même si leurs hypothèses sont un peu violées par le modèle réel à partir duquel les données ont été générées.\n",
    "\n",
    "## Limites\n",
    "\n",
    "* Ils peuvent être aussi complexes, ils ne généralisent pas bien (overfitting: surapprentissage). On peut régler ça en fixant le nombre minimum des échantillons dans les feuilles ou en fixant la profondeur maximale de l'arbre.\n",
    "* Ils peuvent être unstable à cause des variations des données.\n",
    "* Ils existe des conceptes qui sont un peu difficile à apprendre par les arbres de décision. Ils ne sont pas faciles à exprimer, par exemple: XOR.\n",
    "* Ils peuvent être biaisés à la classe dominante. Donc, il faut balancer les données avant d'entrainer le système.\n",
    "* Ce n'ai pas garanti de tomber sur l'arbre de décision optimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- ID3 (Implémentation)\n",
    "\n",
    "L'algorithme ne fonctionne que sur des caractéristiques nominales. \n",
    "Donc, si on a des caractéristiques continues, il faut appliquer la discritésation. \n",
    "Aussi, il est utilisé pour le classement seulement (pas de régression).\n",
    "\n",
    "\n",
    "### I-1- Lecture et préparation des données de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temps</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidite</th>\n",
       "      <th>vent</th>\n",
       "      <th>jouer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temps temperature humidite vent jouer\n",
       "0   ensoleile      chaude    haute  non   non\n",
       "1   ensoleile      chaude    haute  oui   non\n",
       "2     nuageux      chaude    haute  non   oui\n",
       "3    pluvieux       douce    haute  non   oui\n",
       "4    pluvieux     fraiche  normale  non   oui\n",
       "5    pluvieux     fraiche  normale  oui   non\n",
       "6     nuageux     fraiche  normale  oui   oui\n",
       "7   ensoleile       douce    haute  non   non\n",
       "8   ensoleile     fraiche  normale  non   oui\n",
       "9    pluvieux       douce  normale  non   oui\n",
       "10  ensoleile       douce  normale  oui   oui\n",
       "11    nuageux       douce    haute  oui   oui\n",
       "12    nuageux      chaude  normale  non   oui\n",
       "13   pluvieux       douce    haute  oui   non"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "jouer = pd.read_csv(\"datasets/jouer.csv\")\n",
    "jouer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ensoleile', 'chaude', 'haute', 'non'],\n",
       "       ['ensoleile', 'chaude', 'haute', 'oui'],\n",
       "       ['nuageux', 'chaude', 'haute', 'non']], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_jouer = jouer.iloc[:, :-1].values # Premières colonnes \n",
    "Y_jouer = jouer.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "X_jouer[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-2- Probabilité \n",
    "\n",
    "Etant donné un ensemble de valeurs $S$ (dans python: array), la probabilité d'occurence d'une valeur $v$ (une chaine de caractères) est le nombre d'occurence de $v$ dans $S$ divisé par le nombre total des éléments de $S$. \n",
    "\n",
    "$$p(v/S) = \\frac{|\\{x / x \\in S \\text{ et } x = v\\}|}{|S|}$$\n",
    "\n",
    "Exemple, prenons la colonne \"jouer\". \n",
    "Le nombre de \"oui\" est 9 et le nombre total est 14. \n",
    "$$p(jouer=oui) = \\frac{9}{14} = 0.6428571428571429$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6428571428571429,\n",
       " 0.35714285714285715,\n",
       " 0.2857142857142857,\n",
       " 0.35714285714285715)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO calculer la probabilité d'occurence d'une valeur val dans un ensemble S\n",
    "# S est un vecteur (array) de string\n",
    "# PS: si la division retourne toujours 0, essayer d'appliquer float(x)\n",
    "# sur le numérateur ou le dénominateur\n",
    "def P (S, val): \n",
    "    return np.sum(S == val) / S.shape[0]\n",
    "\n",
    "\n",
    "# Calcule manuel 5 chiffres après la virgule (sans arrondissement)\n",
    "# P(jouer=oui) = 9/14 = 0.64285\n",
    "# P(temps = ensoleilé) = 5/14 = 0.35714\n",
    "# P(temps = nuageux) = 4/14 = 0.28571\n",
    "# P(temps = pluvieux) = 5/14 = 0.35714\n",
    "\n",
    "#Résulat: \n",
    "#(0.6428571428571429,\n",
    "# 0.35714285714285715,\n",
    "# 0.2857142857142857,\n",
    "# 0.35714285714285715)\n",
    "\n",
    "P(Y_jouer, \"oui\"), P(X_jouer[:,0], \"ensoleile\"), P(X_jouer[:, 0], \"nuageux\"), P(X_jouer[:,0], \"pluvieux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-3- Incertitude d'un ensemble\n",
    "\n",
    "L'entropie de Shannon correspond à la quantité d'information contenue dans une source d'information ; plus la source émet d'informations différentes, plus l'entropie (ou incertitude sur ce que la source émet) est grande.\n",
    "Donc, un ensemble avec une entropie de 0 contient les mêmes valeurs.\n",
    "Etant donné : \n",
    "- $S$ un ensemble de valeurs \n",
    "- $V$ un ensemble de valeurs uniques de $S$ \n",
    "\n",
    "L'entropie de $S$ est calculée comme suit : \n",
    "$$H(S) = - \\sum\\limits_{v \\in V} p(v/S) \\log_2 p(v/S)$$\n",
    "\n",
    "Par exemple, la colonne \"jouer\" contient deux valeurs \"oui\" et \"non\". \n",
    "Son entopie est :\n",
    "$$H(jouer) = - \\frac{9}{14} * \\log_2(\\frac{9}{14}) - \\frac{5}{14} * \\log_2(\\frac{5}{14}) = 0.9402859586706309$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5774062828523454"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter la fonction d'entropie\n",
    "def H(S):  \n",
    "    vals = np.unique(S)\n",
    "    res = 0\n",
    "    for i in range(vals.shape[0]):\n",
    "        res -= P(S,vals[i])*np.log2(P(S,vals[i]))\n",
    "    # compléter ici\n",
    "    return res \n",
    "\n",
    "# Calcule manuel 5 chiffres après la virgule (sans arrondissement)\n",
    "# H(temps) = - P(temps = ensoleilé) * log2 (P(temps = ensoleilé))\n",
    "#            - P(temps = nuageux) * log2 (P(temps = nuageux))\n",
    "#            - P(temps = pluvieux) * log2 (P(temps = pluvieux))\n",
    "#          = - 5/14 * log2(5/14) - 4/14 * log2(4/14) - 5/14 * log2(5/14)\n",
    "#          = 1.57740 (copier-coller la formule dans Google)\n",
    "\n",
    "#Résultat: 1.5774062828523454\n",
    "\n",
    "H(X_jouer[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-4- Division d'un ensemble\n",
    "\n",
    "Ici, on essaye de diviser l'ensemble des classes selon les valeurs d'un attribut (caractéristique, colonne) à des sous ensembles. \n",
    "\n",
    "Etant donné : \n",
    "- S : l'ensemble à diviser (un vecteur en réalité, puisqu'on doit utiliser l'ordre des éléments)\n",
    "- A : l'ensemble des valeurs d'un attribut (caractéristique, colonne). C'est un vecteur aligné avec S ; c-à-d, chaque élément de A a un élément de S respectif.\n",
    "- val : la valeur sur laquelle on divie.\n",
    "\n",
    "$$S_{A, val} = \\{v_i \\in S / i \\in \\{j / w_j \\in A \\text{ et } w_j = val\\}\\}$$\n",
    "\n",
    "Par exemple, si \n",
    "- $S$ est l'ensemble des classes \"jouer\"\n",
    "- $A$ est l'ensemble des valeurs de caractéristique \"temps\"\n",
    "- $val$ est la valeur \"ensoleile\"\n",
    "La sous ensemble de \"jouer\" où (temps = \"ensoleile\") contient 3 non et 2 oui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non', 'non', 'non', 'oui', 'oui'], dtype='<U32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter la fonction \n",
    "# elle doit rendre un sous ensemble de S\n",
    "# là où les valeurs respectives dans A sont égales à val\n",
    "def diviser(S, A, val):\n",
    "    result = np.array([])\n",
    "    for i in range(A.shape[0]):\n",
    "        if (A[i] == val):\n",
    "            result = np.append(result, S[i])\n",
    "    return result\n",
    "\n",
    "# Résultat : \n",
    "#array(['non', 'non', 'non', 'oui', 'oui'], dtype=object)\n",
    "diviser(Y_jouer, X_jouer[:,0], \"ensoleile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on divise la colonne \"jouer\" (Y_jouer) sur trois sous-ensembles selon les valeurs de la colonne \"temps\". \n",
    "Pour chaque sous-ensemble, on calcule l'entropie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9709505944546686, 0.0, 0.9709505944546686)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ensoleile = diviser(Y_jouer, X_jouer[:,0], \"ensoleile\") # jouer: 2 oui, 3 non\n",
    "# H(S_ensoleilé) = - 2/5 * log2(2/5) - 3/5 * log2(3/5) = 0.9709505944546686\n",
    "Y_nuageux = diviser(Y_jouer, X_jouer[:,0], \"nuageux\") # jouer: 4 oui, 0 non\n",
    "# P(S_nuageux) = - 4/4 * log2(4/4) - 0/4 * log2(0/4) = 0.0\n",
    "Y_pluvieux = diviser(Y_jouer, X_jouer[:,0], \"pluvieux\") # jouer: 3 oui, 2 non\n",
    "# P(S_pluvieux) = - 3/5 * log2(3/5) - 2/5 * log2(2/5) = 0.971\n",
    "\n",
    "# Résultat: \n",
    "# (0.9709505944546686, 0.0, 0.9709505944546686)\n",
    "H(Y_ensoleile), H(Y_nuageux), H(Y_pluvieux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'entropie de l'ensemble (temps = nuageux) égale à 0 \n",
    "\n",
    "**Question** : \n",
    "- Que est ce que ça veut dire ?\n",
    "- Est-ce qu'on a besoin de diviser cette ensemble en utilisant une autre caractéristique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-5- Le gain d'entropie\n",
    "\n",
    "Le gain d'entropie (information gain) est la différence entre l'entropie avant et après la division d'un ensemble $S$ selon l'attribut $A$. \n",
    "En d'autres termes, combien d'incertitude dans $S$ a été réduite après sa division en utilisant l'attribut $A$.\n",
    "\n",
    "Etant donné : \n",
    "- S : un ensemble (dans notre cas, l'ensemble des classes) \n",
    "- A : ensemble des valeurs d'un attribut (caractéristique, colonne) \n",
    "- V : l'ensemble des valeurs différentes de l'attribut A\n",
    "- p(v/A) : la probabité d'occurence de la valeur $v$ dans $A$\n",
    "- $S_{A, v}$ : sous-ensemble de $S$ où les valeurs de $V$ égalent à $v$ \n",
    "\n",
    "Le gain d'entrepie se calcule comme suit : \n",
    "\n",
    "$$IG(S, A) = H(S) - \\sum_{v \\in V} p(v/A) H(S_{A, v})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24674981977443933, 0.9402859586706311)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter cette fonction \n",
    "# elle doit rendre le gain d'entropie et l'entropie \n",
    "# On rend l'entropie pour ne pas recalculer ultérierement \n",
    "def IG(S, A):\n",
    "    vals = np.unique(A)\n",
    "    entropie = H(S)\n",
    "    ig_global = entropie\n",
    "    # compléter ici\n",
    "    for i in range(vals.shape[0]):\n",
    "        ig_global -= P(A,vals[i]) * H(diviser(S, A, vals[i]))\n",
    "    \n",
    "    return ig_global, entropie\n",
    "\n",
    "#    TEST\n",
    "# ===========\n",
    "# IG(S, temps) = H(S) - P(temps = ensoleilé) * H(S_ensoleilé) - P(temps = nuageux) * H(S_nuageux) - P(temps = pluvieux) * H(S_pluvieux)\n",
    "#              = 0.2467498197744391\n",
    "\n",
    "# Résultat : (0.2467498197744391, 0.9402859586706309)\n",
    "IG(Y_jouer, X_jouer[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG(jouer, temps), IG(jouer, température), IG(jouer, humidité), IG(jouer, vent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.24674981977443933, 0.9402859586706311),\n",
       " (0.02922256565895487, 0.9402859586706311),\n",
       " (0.15183550136234164, 0.9402859586706311),\n",
       " (0.048127030408269544, 0.9402859586706311))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"IG(jouer, temps), IG(jouer, température), IG(jouer, humidité), IG(jouer, vent)\")\n",
    "\n",
    "IG(Y_jouer, X_jouer[:, 0]), IG(Y_jouer, X_jouer[:, 1]), IG(Y_jouer, X_jouer[:, 2]), IG(Y_jouer, X_jouer[:, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** \n",
    "- Quelle est la caractéristique qu'on doit utiliser pour diviser le premier noeud de l'arbre?\n",
    "- Pourquoi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.24674981977443933, 0.9402859586706311)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter cette fonction qui cherche la caractéristique \n",
    "# le plus adéquat pour diviser Y \n",
    "# elle doit, aussi, rendre le IG et le H de ce caractéristique \n",
    "def num_caracteristique(X, Y): \n",
    "    num = -1\n",
    "    num_ig = - 1.0\n",
    "    num_h = -1.0\n",
    "    # compléter ici\n",
    "    for i in range(X.shape[1]):\n",
    "        ig, entropie = IG(Y, X[:, i])\n",
    "        if(ig > num_ig):\n",
    "            num = i\n",
    "            num_ig = ig\n",
    "            num_h = entropie\n",
    "    return num, num_ig, num_h\n",
    "\n",
    "# Résultat: (0, 0.2467498197744391, 0.9402859586706309)\n",
    "num_caracteristique(X_jouer, Y_jouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-6- Création de l'arbre\n",
    "\n",
    "**Rien à programmer ou analyser ici.**\n",
    "\n",
    "On crée une structure pour l'arbre (la classe Noeud)\n",
    "\n",
    "On implémente une fonction récursive pour créer une arbre à partir d'un ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Code\n",
      "Si X[0] est \"ensoleile\" Alors\n",
      "    Si X[2] est \"haute\" Alors\n",
      "        Y est \"non\"\n",
      "    Si X[2] est \"normale\" Alors\n",
      "        Y est \"oui\"\n",
      "Si X[0] est \"nuageux\" Alors\n",
      "    Y est \"oui\"\n",
      "Si X[0] est \"pluvieux\" Alors\n",
      "    Si X[3] est \"non\" Alors\n",
      "        Y est \"oui\"\n",
      "    Si X[3] est \"oui\" Alors\n",
      "        Y est \"non\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oui'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Une classe pour contenir les informations du noeud et \n",
    "# la liste de ces fils\n",
    "class Noeud(object): \n",
    "    \n",
    "    nbr = 0\n",
    "    \n",
    "    def __init__(self, num, ig, h, profondeur): \n",
    "        self.num = num # le numéro du caractéristique de dévision dans X\n",
    "        self.ig = ig # le IG de division\n",
    "        self.h = h # l'entropie H\n",
    "        self.pr = profondeur # la profondeur du noeud\n",
    "        self.fils = {} # les fils ; un dictionnaire valeur : noeud\n",
    "        self.cls = \"\" # la classe si ce noeud est final (s'il n'y a pas de fils)\n",
    "        self.indent = \"    \" # indentation lorsqu'on génère le code\n",
    "    \n",
    "    # Cette fonction est pour transformer le noeud à une string\n",
    "    #Ici, nous avons redéfini cette fonction afin qu'elle écrive l'arbre \n",
    "    #sous form d'un algorithme ; c'est un parser \n",
    "    def __str__(self):\n",
    "        \n",
    "        indent = self.indent * self.pr # indentation : esthetique\n",
    "        \n",
    "        # s'il n'y a pas de fils, le noeud est terminal ; on imprime la classe\n",
    "        if (len(self.fils)==0):\n",
    "            return indent + 'Y est \"' + self.cls + '\"\\n'\n",
    "        \n",
    "        # s'il y a des fils, on boucle sur les fils et on imprime des SI ... ALORS\n",
    "        res = \"\"\n",
    "        for valeur in self.fils:\n",
    "            res += indent + 'Si X[' + str(self.num) + '] est \"' + str(valeur) + '\" Alors\\n' + str(self.fils[valeur])\n",
    "        return res\n",
    "    \n",
    "    # predire un échantillon\n",
    "    def predire(self, x): \n",
    "        \n",
    "        # Si le noeud est final, il rend sa classe \n",
    "        if (len(self.fils)==0):\n",
    "            return self.cls\n",
    "        \n",
    "        # Si la valeur de la colonne respective à ce noeud n'appartient pas à l'ensemble des\n",
    "        # valeurs attendues, on rend np.nan\n",
    "        if x[self.num] not in self.fils: \n",
    "            return np.nan\n",
    "        \n",
    "        # Sinon, on rend \n",
    "        return self.fils[x[self.num]].predire(x)\n",
    "    \n",
    "    # générer un code pour graphviz\n",
    "    def graphviz(self): \n",
    "        \n",
    "        nid = 'N' + str(Noeud.nbr)\n",
    "        Noeud.nbr += 1\n",
    "        \n",
    "        # Si le noeud est final, \n",
    "        if (len(self.fils)==0):\n",
    "            return nid, nid + '[label=\"' + self.cls + '\" shape=ellipse];\\n'\n",
    "        \n",
    "        # Sinon, \n",
    "        # s'il y a des fils, on boucle sur les fils et on imprime des SI ... ALORS\n",
    "        res = nid + '[label=\"X[' + str(self.num) + ']\\\\n'\n",
    "        res += 'H = ' + str(self.h) + '\\\\n'\n",
    "        res += 'IG = ' + str(self.ig) + '\"];\\n'\n",
    "        for valeur in self.fils:\n",
    "            vid, code = self.fils[valeur].graphviz()\n",
    "            res += code\n",
    "            res += nid + ' -> ' + vid + ' [label=\"' + valeur + '\"];\\n'\n",
    "        return nid, res\n",
    "    \n",
    "\n",
    "# créer l'arbre de décision à partir d'un ensemble X et Y\n",
    "def entrainer(X, Y, profondeur=0, elagage=False): \n",
    "    # Chercher la meilleure caractéristique de X pour diviser Y\n",
    "    num, num_ig, num_h = num_caracteristique(X, Y)\n",
    "    \n",
    "    # Créer un noeud\n",
    "    noeud = Noeud(num, num_ig, num_h, profondeur)\n",
    "    # Si l'entropie est 0 donc le noeud est une feuille \n",
    "    if num_h == 0.0:\n",
    "        noeud.cls = Y[0] # la classe du noeud\n",
    "        return noeud # retourner le noeud \n",
    "    \n",
    "    # il n'y a pas d'élagage dans ID3, mais il faut l'activer pour éviter \n",
    "    # le problème de la récursivité max \n",
    "    if profondeur > 0 and elagage:\n",
    "        noeud.cls = max(set(Y))\n",
    "        return noeud # retourner le noeud\n",
    "    \n",
    "    # Sinon, si le noeud n'est pas une feuille, on crée ces fils\n",
    "    profondeur += 1 # la profondeur de ces fils\n",
    "    # les fils sont créés à partir des valeurs uniques du meilleur caractéristique\n",
    "    for val in np.unique(X[:, num]):\n",
    "        # Ces trois lignes sont pour récupérer les sous-ensembles X_val, Y_val\n",
    "        # Corresondants à une valeur du meilleur caractéristique\n",
    "        msk = X[:, num] == val \n",
    "        X_val = X[msk]\n",
    "        Y_val = Y[msk]\n",
    "        # On refait la même opération sur l'ensemble (Y_val) d'une manière récursive\n",
    "        fils = entrainer(X_val, Y_val, profondeur, elagage)\n",
    "        # On affecte le noeud créé indexé par la valeur du meilleur caractéristique \n",
    "        # à l'ensemble des fils du noeud courant\n",
    "        noeud.fils[val] = fils\n",
    "    \n",
    "    return noeud\n",
    "\n",
    "arbre_jouer = entrainer(X_jouer, Y_jouer)\n",
    "\n",
    "print(\"Le Code\")\n",
    "print(arbre_jouer)\n",
    "\n",
    "# Tester sur un échantillon\n",
    "arbre_jouer.predire([\"pluvieux\", \"temperature_makanche\", \"humidite_makanche\", \"non\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-7- Regrouper les fonctions ensemble\n",
    "\n",
    "**Rien à programmer ici. Il y a une question à répondre.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si temps est \"ensoleile\" Alors\n",
      "    Si humidite est \"haute\" Alors\n",
      "        jouer est \"non\"\n",
      "    Si humidite est \"normale\" Alors\n",
      "        jouer est \"oui\"\n",
      "Si temps est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Si temps est \"pluvieux\" Alors\n",
      "    Si vent est \"non\" Alors\n",
      "        jouer est \"oui\"\n",
      "    Si vent est \"oui\" Alors\n",
      "        jouer est \"non\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ID3(object): \n",
    "    \n",
    "    def entrainer(self, X, Y, X_noms=[], Y_nom=\"\", elagage=False):\n",
    "        self.arbre = entrainer(X, Y, elagage=elagage)\n",
    "        code = str(self.arbre)\n",
    "        if len(Y_nom) > 0: \n",
    "            code = code.replace(\"Y\", Y_nom)\n",
    "        for i in range(len(X_noms)): \n",
    "            code = code.replace(\"X[\" + str(i) + \"]\", X_noms[i])\n",
    "        self.code = code\n",
    "        self.X_noms = X_noms\n",
    "    \n",
    "    def predire(self, X): \n",
    "        predictions = []\n",
    "        for i in range(len(X)): \n",
    "            predictions.append(self.arbre.predire(X[i, :]))\n",
    "        return predictions\n",
    "    \n",
    "    def graphviz(self): \n",
    "        nid, code = self.arbre.graphviz()\n",
    "        res = \"digraph Tree {\\n\"\n",
    "        res += \"node [shape=box] ;\"\n",
    "        for i in range(len(self.X_noms)): \n",
    "            code = code.replace(\"X[\" + str(i) + \"]\", self.X_noms[i])\n",
    "        res += code\n",
    "        res += \"}\"\n",
    "        return res\n",
    "\n",
    "id3_classifieur = ID3()\n",
    "id3_classifieur.entrainer(X_jouer, Y_jouer, X_noms=[\"temps\", \"temperature\", \"humidite\", \"vent\"], Y_nom=\"jouer\")\n",
    "print(id3_classifieur.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le code, on remarque que l'arbre de décision ne prend pas en considération la caractéristique \"temperature\"\n",
    "\n",
    "**Question** Que pouvez-vous dire à propos de ça?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il faut installer graphviz\n"
     ]
    }
   ],
   "source": [
    "# C'est juste une visualisation du graphe\n",
    "# Si ça ne mmarche pas, ce n'ai pas grave\n",
    "try:\n",
    "    from IPython.display import SVG\n",
    "    from graphviz import Source\n",
    "    from IPython.display import display\n",
    "    \n",
    "    graph = Source(id3_classifieur.graphviz())\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "except ImportError:\n",
    "    print(\"il faut installer graphviz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II- C4.5 \n",
    "\n",
    "**Rien à implémenter ou analyser ici.** \n",
    "\n",
    "Cet algorithme est une amélioration sur l'algorithme ID3.\n",
    "Parmi les améliorations:\n",
    "\n",
    "- Transformer les caractéristiques continues (numériques) en caractéristiques nominales dynamiquement.\n",
    "- Les caractéristiques sans valeurs sont ignorées lors du calcul de l'entropie et le gain d'information.\n",
    "- Élagage des arbres après la création.\n",
    "\n",
    "### II-1- Sélectionner la meilleure caractéristique\n",
    "\n",
    "Lorsqu'on a une caractéristique avec un grand nombre de valeurs, elle sera favorisée par le gain d'entropie (IG). \n",
    "C4.5 utilise une extension du IG appelée \"rapport du gain\"\n",
    "Le rapport de gain fait face au problème de biais en normalisant le gain d'informations à l'aide de l'information de division.\n",
    "\n",
    "\n",
    "Etant donné : \n",
    "- S : un ensemble (dans notre cas, l'ensemble des classes) \n",
    "- A : ensemble des valeurs d'un attribut (caractéristique, colonne) \n",
    "- V : l'ensemble des valeurs différentes de l'attribut A\n",
    "- p(v) : la probabité d'occurence de la valeur $v$ dans $A$\n",
    "- $S_{A, v}$ : sous-ensemble de $S$ où les valeurs de $V$ égalent à $v$ \n",
    "\n",
    "L'information de dévision SI (Split Information) peut être calculée comme suit:\n",
    "$$SI(S, A) = - \\sum_{v \\in V} p(v) H(S_{A, v})$$\n",
    "\n",
    "Et le rapport de gain GR (Gain Ratio) est calculé comme suit:\n",
    "$$GR(S, A) = \\frac{IG(S, A)}{SI(S, A)}$$\n",
    "\n",
    "### II-2- Traitement des caractéristiques continues\n",
    "\n",
    "ID3 ne supporte pas les caractéristiques avec des valeurs continues; comme l'age, le prix, etc.\n",
    "C4.5 introduit le support de ce type de caractéristiques en cherchant le meilleur seuil qui peut diviser l'ensemble des valeurs d'une caractéristique en deux.\n",
    "\n",
    "Afin de sélectionner la bonne division, on suit l'algorithme suivant à chaque fois qu'on veuille comparer une caractéristique avec d'autres:\n",
    "\n",
    "- Pour chaque valeur $v_{A,i}$ d'une caractéristique $A$ \n",
    "    - Diviser l'ensemble de données $S$ en deux sous ensembles: les données avec $ v > v_{A,i}$ et celles avec $ v <= v_{A,i}$\n",
    "    - Calculer le rapport de gain GR de cette division\n",
    "- La valeur qui maximise le rapport de gain est prise comme seuil de dévision\n",
    "\n",
    "### II-3- Élagage des arbres (pruning)\n",
    "\n",
    "Pour éviter le sur-apprentissage (créer un arbre avec une grande profondeur), on peut utiliser la technique d'élagage.\n",
    "Il existe deux types d'élagage:\n",
    "\n",
    "- **pré-élagage** : utiliser des critères d'arrêt de la division. Par exemmple: nombre minimum des échantillons dans un noeud, un taux d'homogénéité d'un sous-ensemble.\n",
    "- **post-élagage** : construire l'arbre, ensuite éliminer les branches qui n'améliorent pas la performance de l'arbre.\n",
    "\n",
    "Voici l'algorithme de post-élagage utilisé par C4.5:\n",
    "\n",
    "- Construire l'arbre de décision\n",
    "- Transformer l'arbre à un ensemble de règles de la forme (Si [preconditions] Alors [résultat]) en traversant l'arbre depuis la racine jusqu'à une feuile.\n",
    "- Supprimer les préconditions qui n'améliorent pas la performance d'une règle.\n",
    "- Arranger les règles élagées en se basant sur leurs performances. On commence par la règle qui donne plus de performance et on se termine par celle qui donne moins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III- CART (implémentation)\n",
    "\n",
    "L'algorithme CART est similaire à celui de C4.5 avec quelques différences :\n",
    "- Il supporte la régression.\n",
    "- Il utilise d'autres critères pour sélectionner la meilleure caractéristique.\n",
    "- Il essaye de minimiser une fonction de coût.\n",
    "- Il utilise le pré-élagage en utilisant un critère d'arrêt.\n",
    "- Il crée des arbres binaires \n",
    "\n",
    "### III-1- Lecture et préparation des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temps</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidite</th>\n",
       "      <th>vent</th>\n",
       "      <th>jouer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>21</td>\n",
       "      <td>70</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>24</td>\n",
       "      <td>80</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ensoleile</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>nuageux</td>\n",
       "      <td>27</td>\n",
       "      <td>75</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>pluvieux</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temps  temperature  humidite vent jouer\n",
       "0   ensoleile           30        85  non   non\n",
       "1   ensoleile           27        90  oui   non\n",
       "2     nuageux           28        78  non   oui\n",
       "3    pluvieux           21        96  non   oui\n",
       "4    pluvieux           20        80  non   oui\n",
       "5    pluvieux           18        70  oui   non\n",
       "6     nuageux           18        65  oui   oui\n",
       "7   ensoleile           22        95  non   non\n",
       "8   ensoleile           21        70  non   oui\n",
       "9    pluvieux           24        80  non   oui\n",
       "10  ensoleile           24        70  oui   oui\n",
       "11    nuageux           22        90  oui   oui\n",
       "12    nuageux           27        75  non   oui\n",
       "13   pluvieux           22        80  oui   non"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importation pour ne pas être obligé d'exécuté le premier code\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "njouer = pd.read_csv(\"datasets/jouer_num.csv\")\n",
    "njouer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ensoleile', 30, 85, 'non'],\n",
       "       ['ensoleile', 27, 90, 'oui'],\n",
       "       ['nuageux', 28, 78, 'non']], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_njouer = njouer.iloc[:, :-1].values # Premières colonnes \n",
    "Y_njouer = njouer.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "X_njouer[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-2- Probabilité \n",
    "\n",
    "Déjà implémentée dans ID3\n",
    "\n",
    "### III-3- Index de diversité de Gini\n",
    "\n",
    "Dans le cas de classement, CART utilise l'indexe de diversité Gini pour mesurer l'erreur de classification.\n",
    "Un index de 0 représente la meilleure division; \n",
    "\n",
    "Etant donné : \n",
    "- $S$ un ensemble de valeurs \n",
    "- $V$ un ensemble de valeurs uniques de $S$ \n",
    "\n",
    "L'index de diversité  $S$ est calculée comme suit : \n",
    "$$Gini(S) = \\sum\\limits_{v \\in V} p(v/S) (1-p(v/S)) = 1 - \\sum\\limits_{v \\in V} p(v/S)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4591836734693877"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter la fonction\n",
    "def Gini(S):  \n",
    "    vals = np.unique(S)\n",
    "    res = 1 \n",
    "    # compléter ici\n",
    "    for i in range(vals.shape[0]):\n",
    "        res -= (P(S,vals[i])) ** 2\n",
    "    return res \n",
    "\n",
    "#Résultat: 0.4591836734693877\n",
    "\n",
    "Gini(Y_njouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-4- Division d'un ensemble\n",
    "\n",
    "Ici, on essaye de diviser l'ensemble des classes $S$ selon les valeurs d'un attribut $A$ (caractéristique, colonne) à deux sous ensembles: gauche $S_G$  et droit $S_D$. \n",
    "\n",
    "**Rien à programmer ici**\n",
    "\n",
    "Les fonctions de dévision rendent deux ensembles : gauche et droite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array(['non', 'non', 'non', 'oui', 'oui'], dtype=object),\n",
       "  array(['oui', 'oui', 'oui', 'non', 'oui', 'oui', 'oui', 'oui', 'non'],\n",
       "        dtype=object)),\n",
       " (array(['non', 'oui'], dtype=object),\n",
       "  array(['non', 'oui', 'oui', 'non', 'oui', 'non', 'oui', 'oui', 'oui',\n",
       "         'oui', 'oui', 'non'], dtype=object)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dans le cas d'une caractéristique nominale A, on rend \n",
    "# l'ensemble gauche S_{A == val} et l'ensemble droit S_{A != val}\n",
    "def diviser_nom_bin(S, A, val):\n",
    "    msk = A == val\n",
    "    return S[msk], S[~msk]\n",
    "\n",
    "# Dans le cas d'une caractéristique numérique A, on rend \n",
    "# l'ensemble gauche S_{A > val} et l'ensemble droit S_{A <= val}\n",
    "def diviser_num_bin(S, A, val):\n",
    "    msk = A > val\n",
    "    return S[msk], S[~msk]\n",
    "\n",
    "#La fonction vérifie si la valeur est numérique ou non\n",
    "#Elle fait appel aux deux fonctions précédentes selon le type\n",
    "def diviser_bin(S, A, val):\n",
    "    try:\n",
    "        val2 = float(val)\n",
    "        return diviser_num_bin(S, A, val)\n",
    "    except ValueError:\n",
    "        return diviser_nom_bin(S, A, val)\n",
    "\n",
    "# Résulat\n",
    "# ((array(['non', 'non', 'non', 'oui', 'oui'], dtype=object),\n",
    "#  array(['oui', 'oui', 'oui', 'non', 'oui', 'oui', 'oui', 'oui', 'non'],\n",
    "#        dtype=object)),\n",
    "# (array(['non', 'oui'], dtype=object),\n",
    "#  array(['non', 'oui', 'oui', 'non', 'oui', 'non', 'oui', 'oui', 'oui',\n",
    "#         'oui', 'oui', 'non'], dtype=object)))\n",
    "diviser_bin(Y_njouer, X_njouer[:, 0], \"ensoleile\"), diviser_bin(Y_njouer, X_njouer[:, 1], 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-5- La diversité Gini de la division\n",
    "\n",
    "Etant donné : \n",
    "- S : un ensemble (dans notre cas, l'ensemble des classes) \n",
    "- V : les différentes valeurs de S \n",
    "- S_G, G_D : sous ensembles gauche et droit\n",
    "- $|S| = |S_G| + |S_D|$\n",
    "\n",
    "La diversité Gini de la division : \n",
    "\n",
    "$$Gini_{div}(S_G, S_D) = \\frac{|S_G|}{|S|} Gini(S_G) + \\frac{|S_D|}{|S|} Gini(S_D)$$\n",
    "\n",
    "Ici, on essaye de minimiser $Gini_{div}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39365079365079364"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter cette fonction\n",
    "def Gini_div(S_G, S_D):  \n",
    "    return (S_G.shape[0]*Gini(S_G) + S_D.shape[0]*Gini(S_D)) / (S_G.shape[0] + S_D.shape[0])\n",
    "\n",
    "# Résultat: 0.3936507936507937\n",
    "Gini_div(*diviser_bin(Y_njouer, X_njouer[:, 0], \"ensoleile\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.35714285714285715, 'nuageux')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO compléter en suivant le pseudo-code\n",
    "# cette fonction qui cherche la caractéristique \n",
    "# ainsi que sa valeur les plus adéquates pour diviser Y \n",
    "# elle doit retourner: \n",
    "# num: l'indice de caractéristique dans X\n",
    "# val: la valeur de dévision (la valeur peut être string ou numérique)\n",
    "# num_gini: le gini de division \n",
    "def choisir_division_cart(X, Y):\n",
    "    num = -1\n",
    "    num_gini = 1.0\n",
    "    num_val = -1.0\n",
    "    # boucler sur les caractéristiques\n",
    "    # boucler sur les différentes valeurs de chaque caractéristique\n",
    "    # diviser sur l'ensemble de la carcatéristique et la valeur\n",
    "    # récupérer Gini \n",
    "    #minimiser gini\n",
    "    for i in range(X.shape[1]):\n",
    "        vals = np.unique(X[:, i])\n",
    "        for j in range(vals.shape[0]):\n",
    "            gini = Gini_div(*diviser_bin(Y, X[:, i], vals[j]))\n",
    "            if(gini < num_gini):\n",
    "                num_gini = gini \n",
    "                num_val = vals[j]\n",
    "                num = i\n",
    "        \n",
    "    return num, num_gini, num_val\n",
    "\n",
    "# Résultat: (0, 0.35714285714285715, 'nuageux')\n",
    "choisir_division_cart(X_jouer, Y_jouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-6-  Élagage des arbres (pruning) et création de l'arbre\n",
    "\n",
    "CART utilise le pré-élagage qu'on le réfère par la condition d'arrêt.\n",
    "Le critère le plus utilisé pour arréter la division est le nombre minimal des échantillons dans un noeud.\n",
    "Si on atteint ce nombre, on ne divise plus et on considère le noeud comme feuille avec la classe dominante comme classe de sortie en cas de classement, ou la moyenne des sorties en cas de régression.\n",
    "\n",
    "**Rien à programmer ici.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Code\n",
      "Si X[0]  est \"nuageux\" Alors\n",
      "    Y est \"oui\"\n",
      "Sinon\n",
      "    Si X[1]  > 24 Alors\n",
      "        Y est \"non\"\n",
      "    Sinon\n",
      "        Si X[1]  > 18 Alors\n",
      "            Si X[1]  > 21 Alors\n",
      "                Y est \"oui\"\n",
      "            Sinon\n",
      "                Y est \"oui\"\n",
      "        Sinon\n",
      "            Y est \"non\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comme Noeud, mais il faut changer un peu, puisqu'on teste sur des \n",
    "# valeurs numériques aussi\n",
    "# Le code sera plus utilisable si on crée une classe commune et on hérite\n",
    "# Mais, je n'ai pas le temps pour tout ça (DEAL WITH IT)\n",
    "class NoeudBin(object): \n",
    "    \n",
    "    nbr = 0\n",
    "    \n",
    "    def __init__(self, num, val, gini, profondeur): \n",
    "        self.num = num # le numéro du caractéristique de dévision dans X\n",
    "        self.val = val\n",
    "        self.gini = gini # le Gini de division\n",
    "        self.pr = profondeur # la profondeur du noeud\n",
    "        self.fils = [] # les fils ; un tableau de deux noeuds: S_G, S_D\n",
    "        self.cls = \"\" # la classe si ce noeud est final (s'il n'y a pas de fils)\n",
    "        self.indent = \"    \" # indentation lorsqu'on génère le code\n",
    "        \n",
    "        try: # le cas d'un numérique\n",
    "            val2 = float(val)\n",
    "            self.est_num = True\n",
    "        except ValueError: # le cas d'un string\n",
    "            self.est_num = False\n",
    "    \n",
    "    # Cette fonction est pour transformer le noeud à une string\n",
    "    #Ici, nous avons redéfini cette fonction afin qu'elle écrive l'arbre \n",
    "    #sous form d'un algorithme ; c'est un parser \n",
    "    def __str__(self):\n",
    "        \n",
    "        indent = self.indent * self.pr # indentation : esthetique\n",
    "        \n",
    "        # s'il n'y a pas de fils, le noeud est terminal ; on imprime la classe\n",
    "        if (len(self.fils)==0):\n",
    "            return indent + 'Y est \"' + self.cls + '\"\\n'\n",
    "        \n",
    "        if (self.est_num): \n",
    "            prefix = ' > '\n",
    "            suffix = ''\n",
    "        else:\n",
    "            prefix = ' est \"'\n",
    "            suffix = '\"'\n",
    "        \n",
    "        # s'il y a des fils, on boucle sur les fils et on imprime des SI ... ALORS SINON\n",
    "        res = \"\"\n",
    "        res += indent + 'Si X[' + str(self.num) + '] ' + prefix + str(self.val) + suffix + ' Alors\\n' + str(self.fils[0])\n",
    "        res += indent + 'Sinon\\n' + str(self.fils[1])\n",
    "        return res\n",
    "    \n",
    "    # predire un échantillon\n",
    "    def predire(self, x): \n",
    "        \n",
    "        # Si le noeud est final, il rend sa classe \n",
    "        if (len(self.fils)==0):\n",
    "            return self.cls\n",
    "        \n",
    "        # sinon\n",
    "        if self.est_num: # le cas d'un numérique\n",
    "            if x[self.num] > self.val:\n",
    "                return self.fils[0].predire(x)\n",
    "            return self.fils[1].predire(x)\n",
    "        \n",
    "        # le cas d'un string\n",
    "        if x[self.num] == val:\n",
    "            return self.fils[0].predire(x)\n",
    "        return self.fils[1].predire(x)\n",
    "\n",
    "    \n",
    "    # générer un code pour graphviz\n",
    "    def graphviz(self): \n",
    "        \n",
    "        nid = 'N' + str(NoeudBin.nbr)\n",
    "        NoeudBin.nbr += 1\n",
    "        \n",
    "        # Si le noeud est final, \n",
    "        if (len(self.fils)==0):\n",
    "            return nid, nid + '[label=\"' + self.cls + '\" shape=ellipse];\\n'\n",
    "        \n",
    "        # Sinon, \n",
    "        # s'il y a des fils, on boucle sur les fils et on imprime des SI ... ALORS\n",
    "        if self.est_num: \n",
    "            prefix = '] > '\n",
    "        else:\n",
    "            prefix = '] = '\n",
    "        res = nid + '[label=\"X[' + str(self.num) + prefix + str(self.val) + '\\\\n'\n",
    "        res += 'Gini = ' + str(self.gini) + '\"];\\n'\n",
    "        vid_G, code_G = self.fils[0].graphviz()\n",
    "        vid_D, code_D = self.fils[1].graphviz()\n",
    "        \n",
    "        res += code_G + code_D\n",
    "        res += nid + ' -> ' + vid_G + ' [label=\"Vrai\"];\\n'\n",
    "        res += nid + ' -> ' + vid_D + ' [label=\"Faux\"];\\n'\n",
    "        return nid, res\n",
    "\n",
    "# créer l'arbre de décision à partir d'un ensemble X et Y\n",
    "def entrainer_cart(X, Y, profondeur=0, nbr_max=3): \n",
    "    \n",
    "    # Chercher le meilleur caractéristique de X pour diviser Y\n",
    "    num, num_gini, num_val = choisir_division_cart(X, Y)\n",
    "    # Créer un noeud\n",
    "    noeud = NoeudBin(num, num_val, num_gini, profondeur)\n",
    "    # Si l'entropie est 0 donc le noeud est terminal, élagage\n",
    "    if (num_gini == 0.0) or (len(Y) <= nbr_max):\n",
    "        noeud.cls = max(set(Y)) # la classe du noeud (la valeur la plus fréquente)\n",
    "        return noeud # retourner le noeud \n",
    "    \n",
    "     \n",
    "    \n",
    "    # Sinon, si le noeud n'est pas terminal, on crée ces fils\n",
    "    profondeur += 1 # la profondeur de ces fils\n",
    "    # création des deux fils\n",
    "    try: # le cas d'un numérique\n",
    "        val2 = float(num_val)\n",
    "        msk = X[:, num] > val2\n",
    "    except ValueError: # le cas d'un string\n",
    "        msk = X[:, num] == num_val\n",
    "    X_G = X[msk]\n",
    "    Y_G = Y[msk]\n",
    "    fils_G = entrainer_cart(X_G, Y_G, profondeur, nbr_max)\n",
    "    X_D = X[~msk]\n",
    "    Y_D = Y[~msk]\n",
    "    fils_D = entrainer_cart(X_D, Y_D, profondeur, nbr_max)\n",
    "    noeud.fils.append(fils_G)\n",
    "    noeud.fils.append(fils_D)\n",
    "    \n",
    "    return noeud\n",
    "\n",
    "arbre_njouer = entrainer_cart(X_njouer, Y_njouer)\n",
    "\n",
    "print(\"Le Code\")\n",
    "print(arbre_njouer)\n",
    "\n",
    "#arbre_jouer.predire([\"pluvieux\", \"temperature_makanche\", \"humidite_makanche\", \"non\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III-7- Regrouper les fonctions ensemble\n",
    "\n",
    "**Rien à programmer ici. Il y a une question à répondre.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si temps  est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Sinon\n",
      "    Si temperature  > 24 Alors\n",
      "        jouer est \"non\"\n",
      "    Sinon\n",
      "        Si temperature  > 18 Alors\n",
      "            Si temperature  > 21 Alors\n",
      "                jouer est \"oui\"\n",
      "            Sinon\n",
      "                jouer est \"oui\"\n",
      "        Sinon\n",
      "            jouer est \"non\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CART(object): \n",
    "    \n",
    "    def entrainer(self, X, Y, X_noms=[], Y_nom=\"\", nbr_max=3):\n",
    "        self.arbre = entrainer_cart(X, Y, 0, nbr_max)\n",
    "        code = str(self.arbre)\n",
    "        if len(Y_nom) > 0: \n",
    "            code = code.replace(\"Y\", Y_nom)\n",
    "        for i in range(len(X_noms)): \n",
    "            code = code.replace(\"X[\" + str(i) + \"]\", X_noms[i])\n",
    "        self.code = code\n",
    "        self.X_noms = X_noms\n",
    "    \n",
    "    def predire(self, X): \n",
    "        predictions = []\n",
    "        for i in range(len(X)): \n",
    "            predictions.append(self.arbre.predire(X[i, :]))\n",
    "        return predictions\n",
    "    \n",
    "    def graphviz(self): \n",
    "        nid, code = self.arbre.graphviz()\n",
    "        res = \"digraph Tree {\\n\"\n",
    "        res += \"node [shape=box] ;\"\n",
    "        for i in range(len(self.X_noms)): \n",
    "            code = code.replace(\"X[\" + str(i) + \"]\", self.X_noms[i])\n",
    "        res += code\n",
    "        res += \"}\"\n",
    "        return res\n",
    "\n",
    "cart_classifieur = CART()\n",
    "cart_classifieur.entrainer(X_njouer, Y_njouer, X_noms=[\"temps\", \"temperature\", \"humidite\", \"vent\"], Y_nom=\"jouer\")\n",
    "print(cart_classifieur.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le code, on remarque que l'arbre de décision ne prend pas en considération les caractéristiques \"humidite\" et \"vent\"\n",
    "\n",
    "**Question** Que pouvez-vous dire à propos de ça?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il faut installer graphviz\n"
     ]
    }
   ],
   "source": [
    "# C'est juste une visualisation du graphe\n",
    "# Si ça ne marche pas, ce n'ai pas grave\n",
    "try:\n",
    "    from IPython.display import SVG\n",
    "    from graphviz import Source\n",
    "    from IPython.display import display\n",
    "    \n",
    "    graph = Source(cart_classifieur.graphviz())\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "except ImportError:\n",
    "    print(\"il faut installer graphviz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV- Comparaison et analyse\n",
    "\n",
    "Ici, vous n'allez pas pogrammer, mais analyser les résultats.\n",
    "\n",
    "### IV-1- Génération de l'arbre \n",
    "\n",
    "Ici, on va comparer entre ID3 et CART selon la génération de l'arbre. Rappel :\n",
    "- ID3\n",
    "    - utilise l'entropie \n",
    "    - le nombre des fils est selon le nombre des valeurs\n",
    "- CART \n",
    "    - utilise l'indice de Gini\n",
    "    - le nombre des fils est binaire\n",
    "    \n",
    "Ici, on va utiliser le dataset \"Jouer\" avec des valeurs nominales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 :\n",
      "Si temps est \"ensoleile\" Alors\n",
      "    Si humidite est \"haute\" Alors\n",
      "        jouer est \"non\"\n",
      "    Si humidite est \"normale\" Alors\n",
      "        jouer est \"oui\"\n",
      "Si temps est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Si temps est \"pluvieux\" Alors\n",
      "    Si vent est \"non\" Alors\n",
      "        jouer est \"oui\"\n",
      "    Si vent est \"oui\" Alors\n",
      "        jouer est \"non\"\n",
      "\n",
      "CART :\n",
      "Si temps  est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Sinon\n",
      "    Si humidite  est \"haute\" Alors\n",
      "        Si temps  est \"ensoleile\" Alors\n",
      "            jouer est \"non\"\n",
      "        Sinon\n",
      "            jouer est \"oui\"\n",
      "    Sinon\n",
      "        Si vent  est \"non\" Alors\n",
      "            jouer est \"oui\"\n",
      "        Sinon\n",
      "            jouer est \"oui\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id3_nom_classifieur = ID3()\n",
    "id3_nom_classifieur.entrainer(X_jouer, Y_jouer, X_noms=[\"temps\", \"temperature\", \"humidite\", \"vent\"], Y_nom=\"jouer\")\n",
    "print(\"ID3 :\")\n",
    "print(id3_nom_classifieur.code)\n",
    "\n",
    "cart_nom_classifieur = CART()\n",
    "cart_nom_classifieur.entrainer(X_jouer, Y_jouer, X_noms=[\"temps\", \"temperature\", \"humidite\", \"vent\"], Y_nom=\"jouer\")\n",
    "print(\"CART :\")\n",
    "print(cart_nom_classifieur.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyser ces résultats** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il faut installer graphviz\n"
     ]
    }
   ],
   "source": [
    "# C'est juste une visualisation du graphe\n",
    "# Si ça ne mmarche pas, ce n'ai pas grave\n",
    "try:\n",
    "    from IPython.display import SVG\n",
    "    from graphviz import Source\n",
    "    from IPython.display import display\n",
    "    \n",
    "    graph1 = Source(id3_nom_classifieur.graphviz())\n",
    "    graph2 = Source(cart_nom_classifieur.graphviz())\n",
    "    display(SVG(graph1.pipe(format='svg')), SVG(graph2.pipe(format='svg')))\n",
    "\n",
    "except ImportError:\n",
    "    print(\"il faut installer graphviz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV-1- Types des attributs\n",
    "\n",
    "Ici, on va comparer entre deux classieurs CART appliqués sur :\n",
    "- données nominales (catégoriques); déjà entrainé\n",
    "- données diverses (numériques et nominales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART avec des caractéristiques nominales :\n",
      "============================================\n",
      "Si temps  est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Sinon\n",
      "    Si humidite  est \"haute\" Alors\n",
      "        Si temps  est \"ensoleile\" Alors\n",
      "            jouer est \"non\"\n",
      "        Sinon\n",
      "            jouer est \"oui\"\n",
      "    Sinon\n",
      "        Si vent  est \"non\" Alors\n",
      "            jouer est \"oui\"\n",
      "        Sinon\n",
      "            jouer est \"oui\"\n",
      "\n",
      "\n",
      "CART avec quelques caractéristiques numériques :\n",
      "================================================\n",
      "Si temps  est \"nuageux\" Alors\n",
      "    jouer est \"oui\"\n",
      "Sinon\n",
      "    Si temperature  > 24 Alors\n",
      "        jouer est \"non\"\n",
      "    Sinon\n",
      "        Si temperature  > 18 Alors\n",
      "            Si temperature  > 21 Alors\n",
      "                jouer est \"oui\"\n",
      "            Sinon\n",
      "                jouer est \"oui\"\n",
      "        Sinon\n",
      "            jouer est \"non\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CART avec des caractéristiques nominales :\")\n",
    "print(\"============================================\")\n",
    "print(cart_nom_classifieur.code)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "cart_num_classifieur = CART()\n",
    "cart_num_classifieur.entrainer(X_njouer, Y_njouer, X_noms=[\"temps\", \"temperature\", \"humidite\", \"vent\"], Y_nom=\"jouer\")\n",
    "\n",
    "print(\"CART avec quelques caractéristiques numériques :\")\n",
    "print(\"================================================\")\n",
    "print(cart_num_classifieur.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyser ces résultats** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il faut installer graphviz\n"
     ]
    }
   ],
   "source": [
    "# C'est juste une visualisation du graphe\n",
    "# Si ça ne mmarche pas, ce n'ai pas grave\n",
    "try:\n",
    "    from IPython.display import SVG\n",
    "    from graphviz import Source\n",
    "    from IPython.display import display\n",
    "    \n",
    "    graph1 = Source(cart_nom_classifieur.graphviz())\n",
    "    graph2 = Source(cart_num_classifieur.graphviz())\n",
    "    display(SVG(graph1.pipe(format='svg')), SVG(graph2.pipe(format='svg')))\n",
    "\n",
    "except ImportError:\n",
    "    print(\"il faut installer graphviz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV-3- Performance\n",
    "\n",
    "On va utiliser [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) pour classer des fleurs en trois classes, en utilisant 4 caractéristiques.\n",
    "\n",
    "Trois modèles vont être utilisés : \n",
    "- ID3 après discritisation des valeurs\n",
    "- CART \n",
    "- scikit-learn \n",
    "\n",
    "Description des métriques : \n",
    "- le support est le nombre des échantillons\n",
    "- pour chaque classe, on fournit la précision, le rappel et le F1 score\n",
    "- micro avg : les métriques (précision, rappel et F1-score) calculées pour la totalité des estimations (util lorsque le nombre des classes est déséquilibré)\n",
    "- macro avg : les métriques calculées pour chaque classe, ensuite on fait la moyenne \n",
    "- weighted avg : les métriques calculées pour chaque classe, multipliées par le support équivalent, sommées, ensuite divisées par le nombre total des échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width            class\n",
       "2             4.7          3.2           1.3          0.2      Iris-setosa\n",
       "41            4.5          2.3           1.3          0.3      Iris-setosa\n",
       "135           7.7          3.0           6.1          2.3   Iris-virginica\n",
       "75            6.6          3.0           4.4          1.4  Iris-versicolor\n",
       "53            5.5          2.3           4.0          1.3  Iris-versicolor"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "iris = pd.read_csv(\"datasets/iris.csv\")\n",
    "iris = iris.sample(frac=1)\n",
    "# Extraction des features \n",
    "X_iris = iris.iloc[:, :-1].values # Premières colonnes \n",
    "\n",
    "Y_iris = iris.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "X_names = list(iris.columns)[:-1]\n",
    "Y_name = list(iris.columns)[-1]\n",
    "\n",
    "# entrainnement\n",
    "iris_msk = np.random.rand(len(X_iris)) < 0.8\n",
    "\n",
    "X_iris_train = X_iris[iris_msk]\n",
    "Y_iris_train = Y_iris[iris_msk]\n",
    "\n",
    "X_iris_test = X_iris[~iris_msk]\n",
    "Y_iris_test = Y_iris[~iris_msk]\n",
    "\n",
    "iris.head()\n",
    "#X_names, Y_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.00      0.00      0.00         8\n",
      " Iris-virginica       0.56      1.00      0.71        10\n",
      "\n",
      "       accuracy                           0.71        28\n",
      "      macro avg       0.52      0.67      0.57        28\n",
      "   weighted avg       0.56      0.71      0.61        28\n",
      "\n",
      "CART\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.75      0.75      0.75         8\n",
      " Iris-virginica       0.80      0.80      0.80        10\n",
      "\n",
      "       accuracy                           0.86        28\n",
      "      macro avg       0.85      0.85      0.85        28\n",
      "   weighted avg       0.86      0.86      0.86        28\n",
      "\n",
      "Scikit-learn\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.78      0.88      0.82         8\n",
      " Iris-virginica       0.89      0.80      0.84        10\n",
      "\n",
      "       accuracy                           0.89        28\n",
      "      macro avg       0.89      0.89      0.89        28\n",
      "   weighted avg       0.90      0.89      0.89        28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T480S\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# ID3 après discritisation \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit(X_iris)\n",
    "X_iris_disc = est.transform(X_iris)\n",
    "X_iris_disc_train = X_iris_disc[iris_msk]\n",
    "id3_iris = ID3()\n",
    "id3_iris.entrainer(X_iris_disc_train, Y_iris_train, X_noms=X_names, Y_nom=Y_name, elagage=True)\n",
    "X_iris_disc_test = X_iris_disc[~iris_msk]\n",
    "id3_iris_res = id3_iris.predire(X_iris_disc_test)\n",
    "\n",
    "# CART \n",
    "cart_iris = CART()\n",
    "cart_iris.entrainer(X_iris_train, Y_iris_train, X_noms=X_names, Y_nom=Y_name)\n",
    "cart_iris_res = cart_iris.predire(X_iris_test)\n",
    "\n",
    "# sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "sklearn_cart_iris = DecisionTreeClassifier()\n",
    "sklearn_cart_iris.fit(X_iris_train, Y_iris_train)\n",
    "sklearn_cart_iris_res = sklearn_cart_iris.predict(X_iris_test)\n",
    "\n",
    "\n",
    "# Le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"ID3\")\n",
    "print(classification_report(Y_iris_test, id3_iris_res))\n",
    "\n",
    "\n",
    "print(\"CART\")\n",
    "print(classification_report(Y_iris_test, cart_iris_res))\n",
    "\n",
    "print(\"Scikit-learn\")\n",
    "print(classification_report(Y_iris_test, sklearn_cart_iris_res))\n",
    "\n",
    "# Ignorer le warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyser ces résultats**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
